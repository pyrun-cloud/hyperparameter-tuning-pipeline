{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "fedcb79d",
   "metadata": {},
   "source": [
    "# Hyperparameter tuning grid search example\n",
    "\n",
    "In this notebook, hyperparameter tuning using grid search algorithm is demonstrated.We have a dataset consisting\n",
    "of amazon product reviews and a sklearn classifier to classiy these reviews. We take advantage of cloud functions\n",
    "to tune this classifier's hyperparameters and show how Lithops can be used for this kind of computations."
   ]
  },
  {
   "cell_type": "markdown",
   "id": "0ca0fd11",
   "metadata": {},
   "source": [
    "## Installing Dependencies"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "81f22288",
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn.feature_extraction.text import HashingVectorizer\n",
    "from sklearn.linear_model import SGDClassifier\n",
    "from sklearn.pipeline import Pipeline\n",
    "\n",
    "import joblib\n",
    "\n",
    "from pprint import pprint\n",
    "from time import time\n",
    "import bz2"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "c8003720",
   "metadata": {},
   "source": [
    "## Downloading the Dataset\n",
    "\n",
    "The dataset should be downloaded and extracted from zip file before this step. \n",
    "`load_data` function seperates the data as X and Y arrays to prepare them for classifier."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "101ae743",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Path to dataset files: /home/pyrunuser/.cache/kagglehub/datasets/bittlingmayer/amazonreviews/versions/7\n"
     ]
    }
   ],
   "source": [
    "import kagglehub\n",
    "\n",
    "# Download latest version\n",
    "path = kagglehub.dataset_download(\"bittlingmayer/amazonreviews\")\n",
    "\n",
    "print(\"Path to dataset files:\", path)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "id": "fb189d1c",
   "metadata": {},
   "outputs": [],
   "source": [
    "path = kagglehub.dataset_download(\"bittlingmayer/amazonreviews\")\n",
    "def load_data(mib):\n",
    "    # Download the dataset at\n",
    "    # https://www.kaggle.com/bittlingmayer/amazonreviews\n",
    "\n",
    "    print(\"Loading Amazon reviews dataset:\")\n",
    "    compressed = bz2.BZ2File(path + \"/\" + \"train.ft.txt.bz2\")\n",
    "\n",
    "    X = []\n",
    "    y = []\n",
    "    total_size = 0\n",
    "    for _ in range(3_600_000):\n",
    "        line = compressed.readline().decode('utf-8')\n",
    "        X.append(line[11:])\n",
    "        y.append(int(line[9]) - 1)  # __label__1, __label__2\n",
    "\n",
    "        total_size += len(line[11:])\n",
    "        if (total_size / 2 ** 20) > mib:\n",
    "            break\n",
    "\n",
    "    print(\"\\t%d reviews\" % len(X))\n",
    "    print(\"\\t%0.2f MiB of data\" % (total_size / 2 ** 20))\n",
    "    return X, y"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "1169baf5",
   "metadata": {},
   "source": [
    "## Execution\n",
    "\n",
    "In the main function, grid search is performed using GridSearchCV from sklearn library with different parameters depending on the backend chosen. "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "id": "1159dd39",
   "metadata": {
    "scrolled": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Loading Amazon reviews dataset:\n",
      "\t23978 reviews\n",
      "\t10.00 MiB of data\n",
      "pipeline: ['vect', 'clf']\n",
      "parameters: {'clf__alpha': (0.01, 0.001, 0.0001, 1e-05),\n",
      " 'clf__max_iter': (20, 60, 100, 160),\n",
      " 'clf__penalty': ('l2', 'l1', 'elasticnet'),\n",
      " 'vect__ngram_range': ((1, 1), (1, 2)),\n",
      " 'vect__norm': ('l1', 'l2')}\n",
      "Performing grid search...\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "2025-03-24 10:18:05,251 [INFO] config.py:146 -- Lithops v3.5.2.dev0 - Python3.10\n",
      "2025-03-24 10:18:05,252 [DEBUG] config.py:107 -- Loading configuration from the cloud\n",
      "2025-03-24 10:18:05,562 [DEBUG] config.py:186 -- Loading Serverless backend module: aws_lambda\n",
      "2025-03-24 10:18:05,563 [DEBUG] config.py:226 -- Loading Storage backend module: aws_s3\n",
      "2025-03-24 10:18:05,564 [DEBUG] aws_s3.py:36 -- Creating AWS S3 Client\n",
      "2025-03-24 10:18:05,733 [INFO] aws_s3.py:59 -- S3 client created - Region: us-east-1\n",
      "2025-03-24 10:18:05,777 [DEBUG] aws_lambda.py:53 -- Creating AWS Lambda client\n",
      "2025-03-24 10:18:05,955 [INFO] aws_lambda.py:97 -- AWS Lambda client created - Region: us-east-1\n",
      "2025-03-24 10:18:05,959 [DEBUG] invokers.py:105 -- ExecutorID 983ab7-0 - Invoker initialized. Max workers: 1000\n",
      "2025-03-24 10:18:05,960 [DEBUG] invokers.py:309 -- ExecutorID 983ab7-0 - Serverless invoker created\n",
      "2025-03-24 10:18:06,154 [DEBUG] executors.py:164 -- Function executor for aws_lambda created with ID: 983ab7-0\n",
      "2025-03-24 10:18:06,731 [INFO] lithops_backend.py:126 -- Optimizing shared data between tasks\n",
      "2025-03-24 10:18:06,851 [DEBUG] config.py:107 -- Loading configuration from the cloud\n",
      "2025-03-24 10:18:07,107 [DEBUG] config.py:226 -- Loading Storage backend module: aws_s3\n",
      "2025-03-24 10:18:07,109 [DEBUG] aws_s3.py:36 -- Creating AWS S3 Client\n",
      "2025-03-24 10:18:07,252 [INFO] aws_s3.py:59 -- S3 client created - Region: us-east-1\n",
      "2025-03-24 10:18:07,254 [DEBUG] lithops_backend.py:152 -- Proxying <class 'list'>\n",
      "2025-03-24 10:18:07,256 [DEBUG] lithops_backend.py:152 -- Proxying <class 'list'>\n",
      "2025-03-24 10:18:07,280 [DEBUG] lithops_backend.py:152 -- Proxying <class 'numpy.ndarray'>\n",
      "2025-03-24 10:18:07,285 [DEBUG] lithops_backend.py:152 -- Proxying <class 'numpy.ndarray'>\n",
      "2025-03-24 10:18:07,302 [DEBUG] lithops_backend.py:152 -- Proxying <class 'numpy.ndarray'>\n",
      "2025-03-24 10:18:07,302 [DEBUG] lithops_backend.py:152 -- Proxying <class 'numpy.ndarray'>\n",
      "2025-03-24 10:18:07,304 [DEBUG] lithops_backend.py:152 -- Proxying <class 'numpy.ndarray'>\n",
      "2025-03-24 10:18:07,305 [DEBUG] lithops_backend.py:152 -- Proxying <class 'numpy.ndarray'>\n",
      "2025-03-24 10:18:07,318 [DEBUG] lithops_backend.py:152 -- Proxying <class 'numpy.ndarray'>\n",
      "2025-03-24 10:18:07,319 [DEBUG] lithops_backend.py:152 -- Proxying <class 'numpy.ndarray'>\n",
      "2025-03-24 10:18:07,335 [DEBUG] lithops_backend.py:152 -- Proxying <class 'numpy.ndarray'>\n",
      "2025-03-24 10:18:07,335 [DEBUG] lithops_backend.py:152 -- Proxying <class 'numpy.ndarray'>\n",
      "2025-03-24 10:18:07,531 [DEBUG] aws_s3.py:106 -- PUT Object lithops.jobs/tmp/983ab7/cloudobject_4 - Size: 150.0KiB - OK\n",
      "2025-03-24 10:18:07,536 [DEBUG] aws_s3.py:106 -- PUT Object lithops.jobs/tmp/983ab7/cloudobject_1 - Size: 46.9KiB - OK\n",
      "2025-03-24 10:18:07,540 [DEBUG] aws_s3.py:106 -- PUT Object lithops.jobs/tmp/983ab7/cloudobject_7 - Size: 37.6KiB - OK\n",
      "2025-03-24 10:18:07,555 [DEBUG] aws_s3.py:106 -- PUT Object lithops.jobs/tmp/983ab7/cloudobject_2 - Size: 150.0KiB - OK\n",
      "2025-03-24 10:18:07,562 [DEBUG] aws_s3.py:106 -- PUT Object lithops.jobs/tmp/983ab7/cloudobject_5 - Size: 37.6KiB - OK\n",
      "2025-03-24 10:18:07,565 [DEBUG] aws_s3.py:106 -- PUT Object lithops.jobs/tmp/983ab7/cloudobject_6 - Size: 150.0KiB - OK\n",
      "2025-03-24 10:18:07,624 [DEBUG] aws_s3.py:106 -- PUT Object lithops.jobs/tmp/983ab7/cloudobject_8 - Size: 150.0KiB - OK\n",
      "2025-03-24 10:18:07,630 [DEBUG] aws_s3.py:106 -- PUT Object lithops.jobs/tmp/983ab7/cloudobject_b - Size: 37.6KiB - OK\n",
      "2025-03-24 10:18:07,644 [DEBUG] aws_s3.py:106 -- PUT Object lithops.jobs/tmp/983ab7/cloudobject_9 - Size: 37.6KiB - OK\n",
      "2025-03-24 10:18:07,698 [DEBUG] aws_s3.py:106 -- PUT Object lithops.jobs/tmp/983ab7/cloudobject_a - Size: 150.0KiB - OK\n",
      "2025-03-24 10:18:07,701 [DEBUG] aws_s3.py:106 -- PUT Object lithops.jobs/tmp/983ab7/cloudobject_3 - Size: 37.6KiB - OK\n",
      "2025-03-24 10:18:08,602 [DEBUG] aws_s3.py:106 -- PUT Object lithops.jobs/tmp/983ab7/cloudobject_0 - Size: 10.1MiB - OK\n",
      "2025-03-24 10:18:08,619 [INFO] invokers.py:119 -- ExecutorID 983ab7-0 | JobID M000 - Selected Runtime: runtime-926779ec-a09e-4d3b-adc3-98f63027c372:05eb2a37-8795-4614-b4c4-c5c1895a28c0-amd64 - 256MB\n",
      "2025-03-24 10:18:08,620 [DEBUG] storage.py:483 -- Runtime metadata not found in local cache. Retrieving it from storage\n",
      "2025-03-24 10:18:08,622 [DEBUG] storage.py:487 -- Trying to download runtime metadata from: aws_s3://lithopscloud-bucket-eftk5pvx5np5/lithops.runtimes/aws_lambda/3.5.2.dev0/us-east-1/lithops-worker-f7yr-352dev0-5478046c9f.meta.json\n",
      "2025-03-24 10:18:08,643 [DEBUG] storage.py:509 -- Runtime metadata not found in storage\n",
      "2025-03-24 10:18:08,644 [INFO] invokers.py:127 -- Runtime runtime-926779ec-a09e-4d3b-adc3-98f63027c372:05eb2a37-8795-4614-b4c4-c5c1895a28c0-amd64 with 256MB is not yet deployed\n",
      "2025-03-24 10:18:08,645 [INFO] aws_lambda.py:448 -- Deploying runtime: runtime-926779ec-a09e-4d3b-adc3-98f63027c372:05eb2a37-8795-4614-b4c4-c5c1895a28c0-amd64 - Memory: 256 Timeout: 180\n",
      "2025-03-24 10:18:34,597 [DEBUG] aws_lambda.py:155 -- \"lithops-worker-f7yr-352dev0-5478046c9f\" function is being deployed... (status: Pending)\n",
      "2025-03-24 10:18:34,684 [DEBUG] aws_lambda.py:165 -- Ok --> function \"lithops-worker-f7yr-352dev0-5478046c9f\" is active\n",
      "2025-03-24 10:18:34,685 [DEBUG] aws_lambda.py:528 -- OK --> Created lambda function lithops-worker-f7yr-352dev0-5478046c9f\n",
      "2025-03-24 10:18:34,687 [DEBUG] aws_lambda.py:712 -- Extracting runtime metadata from: runtime-926779ec-a09e-4d3b-adc3-98f63027c372:05eb2a37-8795-4614-b4c4-c5c1895a28c0-amd64\n",
      "2025-03-24 10:18:40,765 [DEBUG] storage.py:520 -- Uploading runtime metadata to: aws_s3://lithopscloud-bucket-eftk5pvx5np5/lithops.runtimes/aws_lambda/3.5.2.dev0/us-east-1/lithops-worker-f7yr-352dev0-5478046c9f.meta.json\n",
      "2025-03-24 10:18:40,837 [DEBUG] aws_s3.py:106 -- PUT Object lithops.runtimes/aws_lambda/3.5.2.dev0/us-east-1/lithops-worker-f7yr-352dev0-5478046c9f.meta.json - Size: 7.6KiB - OK\n",
      "2025-03-24 10:18:40,838 [DEBUG] storage.py:526 -- Storing runtime metadata into local cache: /home/pyrunuser/.lithops/cache/lithops.runtimes/aws_lambda/3.5.2.dev0/us-east-1/lithops-worker-f7yr-352dev0-5478046c9f.meta.json\n",
      "2025-03-24 10:18:40,975 [DEBUG] job.py:242 -- ExecutorID 983ab7-0 | JobID M000 - Serializing function and data\n",
      "2025-03-24 10:18:43,248 [DEBUG] serialize.py:75 -- Referenced Modules: lithops, traceback, diskcache, concurrent, os\n",
      "2025-03-24 10:18:43,249 [DEBUG] module_dependency.py:109 -- Module 'lithops' is already installed in the runtime, skipping\n",
      "2025-03-24 10:18:43,250 [DEBUG] module_dependency.py:109 -- Module 'traceback' is already installed in the runtime, skipping\n",
      "2025-03-24 10:18:43,251 [DEBUG] module_dependency.py:109 -- Module 'diskcache' is already installed in the runtime, skipping\n",
      "2025-03-24 10:18:43,251 [DEBUG] module_dependency.py:109 -- Module 'concurrent' is already installed in the runtime, skipping\n",
      "2025-03-24 10:18:43,252 [DEBUG] module_dependency.py:109 -- Module 'os' is already installed in the runtime, skipping\n",
      "2025-03-24 10:18:43,253 [DEBUG] serialize.py:120 -- Modules to transmit: None\n",
      "2025-03-24 10:18:43,254 [DEBUG] pool.py:197 -- closing pool\n",
      "2025-03-24 10:18:43,256 [DEBUG] pool.py:202 -- terminating pool\n",
      "2025-03-24 10:18:43,353 [INFO] config.py:146 -- Lithops v3.5.2.dev0 - Python3.10\n",
      "2025-03-24 10:18:43,354 [DEBUG] config.py:107 -- Loading configuration from the cloud\n",
      "2025-03-24 10:18:43,618 [DEBUG] config.py:186 -- Loading Serverless backend module: aws_lambda\n",
      "2025-03-24 10:18:43,621 [DEBUG] config.py:226 -- Loading Storage backend module: aws_s3\n",
      "2025-03-24 10:18:43,624 [DEBUG] aws_s3.py:36 -- Creating AWS S3 Client\n",
      "2025-03-24 10:18:43,787 [INFO] aws_s3.py:59 -- S3 client created - Region: us-east-1\n",
      "2025-03-24 10:18:43,831 [DEBUG] aws_lambda.py:53 -- Creating AWS Lambda client\n",
      "2025-03-24 10:18:44,003 [INFO] aws_lambda.py:97 -- AWS Lambda client created - Region: us-east-1\n",
      "2025-03-24 10:18:44,006 [DEBUG] invokers.py:105 -- ExecutorID 983ab7-1 - Invoker initialized. Max workers: 1000\n",
      "2025-03-24 10:18:44,007 [DEBUG] invokers.py:309 -- ExecutorID 983ab7-1 - Serverless invoker created\n",
      "2025-03-24 10:18:44,196 [DEBUG] executors.py:164 -- Function executor for aws_lambda created with ID: 983ab7-1\n",
      "2025-03-24 10:18:44,197 [DEBUG] pool.py:197 -- closing pool\n",
      "2025-03-24 10:18:44,198 [DEBUG] pool.py:202 -- terminating pool\n"
     ]
    },
    {
     "ename": "Exception",
     "evalue": "ExecutorID 983ab7-0 | JobID M000 - Total data exceeded maximum size of 4.0MiB",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mException\u001b[0m                                 Traceback (most recent call last)",
      "Cell \u001b[0;32mIn[6], line 86\u001b[0m\n\u001b[1;32m     83\u001b[0m             \u001b[38;5;28mprint\u001b[39m(\u001b[38;5;124m\"\u001b[39m\u001b[38;5;130;01m\\t\u001b[39;00m\u001b[38;5;132;01m%s\u001b[39;00m\u001b[38;5;124m: \u001b[39m\u001b[38;5;132;01m%r\u001b[39;00m\u001b[38;5;124m\"\u001b[39m \u001b[38;5;241m%\u001b[39m (param_name, best_parameters[param_name]))\n\u001b[1;32m     85\u001b[0m \u001b[38;5;28;01mif\u001b[39;00m \u001b[38;5;18m__name__\u001b[39m \u001b[38;5;241m==\u001b[39m \u001b[38;5;124m\"\u001b[39m\u001b[38;5;124m__main__\u001b[39m\u001b[38;5;124m\"\u001b[39m:\n\u001b[0;32m---> 86\u001b[0m     \u001b[43mmain\u001b[49m\u001b[43m(\u001b[49m\u001b[38;5;124;43m\"\u001b[39;49m\u001b[38;5;124;43mlithops\u001b[39;49m\u001b[38;5;124;43m\"\u001b[39;49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;28;43;01mNone\u001b[39;49;00m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;241;43m10\u001b[39;49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;28;43;01mFalse\u001b[39;49;00m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;241;43m-\u001b[39;49m\u001b[38;5;241;43m1\u001b[39;49m\u001b[43m)\u001b[49m\n",
      "Cell \u001b[0;32mIn[6], line 74\u001b[0m, in \u001b[0;36mmain\u001b[0;34m(backend, address, mib, refit, jobs)\u001b[0m\n\u001b[1;32m     72\u001b[0m \u001b[38;5;28mprint\u001b[39m(\u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mPerforming grid search...\u001b[39m\u001b[38;5;124m\"\u001b[39m)\n\u001b[1;32m     73\u001b[0m t0 \u001b[38;5;241m=\u001b[39m time()\n\u001b[0;32m---> 74\u001b[0m \u001b[43mgrid_search\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mfit\u001b[49m\u001b[43m(\u001b[49m\u001b[43mX\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43my\u001b[49m\u001b[43m)\u001b[49m\n\u001b[1;32m     75\u001b[0m total_time \u001b[38;5;241m=\u001b[39m time() \u001b[38;5;241m-\u001b[39m t0\n\u001b[1;32m     76\u001b[0m \u001b[38;5;28mprint\u001b[39m(\u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mDone in \u001b[39m\u001b[38;5;132;01m%0.3f\u001b[39;00m\u001b[38;5;124ms\u001b[39m\u001b[38;5;130;01m\\n\u001b[39;00m\u001b[38;5;124m\"\u001b[39m \u001b[38;5;241m%\u001b[39m total_time) \n",
      "File \u001b[0;32m/opt/conda/lib/python3.10/site-packages/sklearn/base.py:1151\u001b[0m, in \u001b[0;36m_fit_context.<locals>.decorator.<locals>.wrapper\u001b[0;34m(estimator, *args, **kwargs)\u001b[0m\n\u001b[1;32m   1144\u001b[0m     estimator\u001b[38;5;241m.\u001b[39m_validate_params()\n\u001b[1;32m   1146\u001b[0m \u001b[38;5;28;01mwith\u001b[39;00m config_context(\n\u001b[1;32m   1147\u001b[0m     skip_parameter_validation\u001b[38;5;241m=\u001b[39m(\n\u001b[1;32m   1148\u001b[0m         prefer_skip_nested_validation \u001b[38;5;129;01mor\u001b[39;00m global_skip_validation\n\u001b[1;32m   1149\u001b[0m     )\n\u001b[1;32m   1150\u001b[0m ):\n\u001b[0;32m-> 1151\u001b[0m     \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[43mfit_method\u001b[49m\u001b[43m(\u001b[49m\u001b[43mestimator\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[43margs\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[43mkwargs\u001b[49m\u001b[43m)\u001b[49m\n",
      "File \u001b[0;32m/opt/conda/lib/python3.10/site-packages/sklearn/model_selection/_search.py:898\u001b[0m, in \u001b[0;36mBaseSearchCV.fit\u001b[0;34m(self, X, y, groups, **fit_params)\u001b[0m\n\u001b[1;32m    892\u001b[0m     results \u001b[38;5;241m=\u001b[39m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_format_results(\n\u001b[1;32m    893\u001b[0m         all_candidate_params, n_splits, all_out, all_more_results\n\u001b[1;32m    894\u001b[0m     )\n\u001b[1;32m    896\u001b[0m     \u001b[38;5;28;01mreturn\u001b[39;00m results\n\u001b[0;32m--> 898\u001b[0m \u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43m_run_search\u001b[49m\u001b[43m(\u001b[49m\u001b[43mevaluate_candidates\u001b[49m\u001b[43m)\u001b[49m\n\u001b[1;32m    900\u001b[0m \u001b[38;5;66;03m# multimetric is determined here because in the case of a callable\u001b[39;00m\n\u001b[1;32m    901\u001b[0m \u001b[38;5;66;03m# self.scoring the return type is only known after calling\u001b[39;00m\n\u001b[1;32m    902\u001b[0m first_test_score \u001b[38;5;241m=\u001b[39m all_out[\u001b[38;5;241m0\u001b[39m][\u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mtest_scores\u001b[39m\u001b[38;5;124m\"\u001b[39m]\n",
      "File \u001b[0;32m/opt/conda/lib/python3.10/site-packages/sklearn/model_selection/_search.py:1419\u001b[0m, in \u001b[0;36mGridSearchCV._run_search\u001b[0;34m(self, evaluate_candidates)\u001b[0m\n\u001b[1;32m   1417\u001b[0m \u001b[38;5;28;01mdef\u001b[39;00m\u001b[38;5;250m \u001b[39m\u001b[38;5;21m_run_search\u001b[39m(\u001b[38;5;28mself\u001b[39m, evaluate_candidates):\n\u001b[1;32m   1418\u001b[0m \u001b[38;5;250m    \u001b[39m\u001b[38;5;124;03m\"\"\"Search all candidates in param_grid\"\"\"\u001b[39;00m\n\u001b[0;32m-> 1419\u001b[0m     \u001b[43mevaluate_candidates\u001b[49m\u001b[43m(\u001b[49m\u001b[43mParameterGrid\u001b[49m\u001b[43m(\u001b[49m\u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mparam_grid\u001b[49m\u001b[43m)\u001b[49m\u001b[43m)\u001b[49m\n",
      "File \u001b[0;32m/opt/conda/lib/python3.10/site-packages/sklearn/model_selection/_search.py:845\u001b[0m, in \u001b[0;36mBaseSearchCV.fit.<locals>.evaluate_candidates\u001b[0;34m(candidate_params, cv, more_results)\u001b[0m\n\u001b[1;32m    837\u001b[0m \u001b[38;5;28;01mif\u001b[39;00m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mverbose \u001b[38;5;241m>\u001b[39m \u001b[38;5;241m0\u001b[39m:\n\u001b[1;32m    838\u001b[0m     \u001b[38;5;28mprint\u001b[39m(\n\u001b[1;32m    839\u001b[0m         \u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mFitting \u001b[39m\u001b[38;5;132;01m{0}\u001b[39;00m\u001b[38;5;124m folds for each of \u001b[39m\u001b[38;5;132;01m{1}\u001b[39;00m\u001b[38;5;124m candidates,\u001b[39m\u001b[38;5;124m\"\u001b[39m\n\u001b[1;32m    840\u001b[0m         \u001b[38;5;124m\"\u001b[39m\u001b[38;5;124m totalling \u001b[39m\u001b[38;5;132;01m{2}\u001b[39;00m\u001b[38;5;124m fits\u001b[39m\u001b[38;5;124m\"\u001b[39m\u001b[38;5;241m.\u001b[39mformat(\n\u001b[1;32m    841\u001b[0m             n_splits, n_candidates, n_candidates \u001b[38;5;241m*\u001b[39m n_splits\n\u001b[1;32m    842\u001b[0m         )\n\u001b[1;32m    843\u001b[0m     )\n\u001b[0;32m--> 845\u001b[0m out \u001b[38;5;241m=\u001b[39m \u001b[43mparallel\u001b[49m\u001b[43m(\u001b[49m\n\u001b[1;32m    846\u001b[0m \u001b[43m    \u001b[49m\u001b[43mdelayed\u001b[49m\u001b[43m(\u001b[49m\u001b[43m_fit_and_score\u001b[49m\u001b[43m)\u001b[49m\u001b[43m(\u001b[49m\n\u001b[1;32m    847\u001b[0m \u001b[43m        \u001b[49m\u001b[43mclone\u001b[49m\u001b[43m(\u001b[49m\u001b[43mbase_estimator\u001b[49m\u001b[43m)\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m    848\u001b[0m \u001b[43m        \u001b[49m\u001b[43mX\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m    849\u001b[0m \u001b[43m        \u001b[49m\u001b[43my\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m    850\u001b[0m \u001b[43m        \u001b[49m\u001b[43mtrain\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mtrain\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m    851\u001b[0m \u001b[43m        \u001b[49m\u001b[43mtest\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mtest\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m    852\u001b[0m \u001b[43m        \u001b[49m\u001b[43mparameters\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mparameters\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m    853\u001b[0m \u001b[43m        \u001b[49m\u001b[43msplit_progress\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43m(\u001b[49m\u001b[43msplit_idx\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mn_splits\u001b[49m\u001b[43m)\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m    854\u001b[0m \u001b[43m        \u001b[49m\u001b[43mcandidate_progress\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43m(\u001b[49m\u001b[43mcand_idx\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mn_candidates\u001b[49m\u001b[43m)\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m    855\u001b[0m \u001b[43m        \u001b[49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[43mfit_and_score_kwargs\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m    856\u001b[0m \u001b[43m    \u001b[49m\u001b[43m)\u001b[49m\n\u001b[1;32m    857\u001b[0m \u001b[43m    \u001b[49m\u001b[38;5;28;43;01mfor\u001b[39;49;00m\u001b[43m \u001b[49m\u001b[43m(\u001b[49m\u001b[43mcand_idx\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mparameters\u001b[49m\u001b[43m)\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43m(\u001b[49m\u001b[43msplit_idx\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43m(\u001b[49m\u001b[43mtrain\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mtest\u001b[49m\u001b[43m)\u001b[49m\u001b[43m)\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;129;43;01min\u001b[39;49;00m\u001b[43m \u001b[49m\u001b[43mproduct\u001b[49m\u001b[43m(\u001b[49m\n\u001b[1;32m    858\u001b[0m \u001b[43m        \u001b[49m\u001b[38;5;28;43menumerate\u001b[39;49m\u001b[43m(\u001b[49m\u001b[43mcandidate_params\u001b[49m\u001b[43m)\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;28;43menumerate\u001b[39;49m\u001b[43m(\u001b[49m\u001b[43mcv\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43msplit\u001b[49m\u001b[43m(\u001b[49m\u001b[43mX\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43my\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mgroups\u001b[49m\u001b[43m)\u001b[49m\u001b[43m)\u001b[49m\n\u001b[1;32m    859\u001b[0m \u001b[43m    \u001b[49m\u001b[43m)\u001b[49m\n\u001b[1;32m    860\u001b[0m \u001b[43m\u001b[49m\u001b[43m)\u001b[49m\n\u001b[1;32m    862\u001b[0m \u001b[38;5;28;01mif\u001b[39;00m \u001b[38;5;28mlen\u001b[39m(out) \u001b[38;5;241m<\u001b[39m \u001b[38;5;241m1\u001b[39m:\n\u001b[1;32m    863\u001b[0m     \u001b[38;5;28;01mraise\u001b[39;00m \u001b[38;5;167;01mValueError\u001b[39;00m(\n\u001b[1;32m    864\u001b[0m         \u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mNo fits were performed. \u001b[39m\u001b[38;5;124m\"\u001b[39m\n\u001b[1;32m    865\u001b[0m         \u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mWas the CV iterator empty? \u001b[39m\u001b[38;5;124m\"\u001b[39m\n\u001b[1;32m    866\u001b[0m         \u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mWere there no candidates?\u001b[39m\u001b[38;5;124m\"\u001b[39m\n\u001b[1;32m    867\u001b[0m     )\n",
      "File \u001b[0;32m/opt/conda/lib/python3.10/site-packages/sklearn/utils/parallel.py:65\u001b[0m, in \u001b[0;36mParallel.__call__\u001b[0;34m(self, iterable)\u001b[0m\n\u001b[1;32m     60\u001b[0m config \u001b[38;5;241m=\u001b[39m get_config()\n\u001b[1;32m     61\u001b[0m iterable_with_config \u001b[38;5;241m=\u001b[39m (\n\u001b[1;32m     62\u001b[0m     (_with_config(delayed_func, config), args, kwargs)\n\u001b[1;32m     63\u001b[0m     \u001b[38;5;28;01mfor\u001b[39;00m delayed_func, args, kwargs \u001b[38;5;129;01min\u001b[39;00m iterable\n\u001b[1;32m     64\u001b[0m )\n\u001b[0;32m---> 65\u001b[0m \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[38;5;28;43msuper\u001b[39;49m\u001b[43m(\u001b[49m\u001b[43m)\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[38;5;21;43m__call__\u001b[39;49m\u001b[43m(\u001b[49m\u001b[43miterable_with_config\u001b[49m\u001b[43m)\u001b[49m\n",
      "File \u001b[0;32m/opt/conda/lib/python3.10/site-packages/joblib/parallel.py:2005\u001b[0m, in \u001b[0;36mParallel.__call__\u001b[0;34m(self, iterable)\u001b[0m\n\u001b[1;32m   1999\u001b[0m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_call_ref \u001b[38;5;241m=\u001b[39m weakref\u001b[38;5;241m.\u001b[39mref(output)\n\u001b[1;32m   2001\u001b[0m \u001b[38;5;66;03m# The first item from the output is blank, but it makes the interpreter\u001b[39;00m\n\u001b[1;32m   2002\u001b[0m \u001b[38;5;66;03m# progress until it enters the Try/Except block of the generator and\u001b[39;00m\n\u001b[1;32m   2003\u001b[0m \u001b[38;5;66;03m# reaches the first `yield` statement. This starts the asynchronous\u001b[39;00m\n\u001b[1;32m   2004\u001b[0m \u001b[38;5;66;03m# dispatch of the tasks to the workers.\u001b[39;00m\n\u001b[0;32m-> 2005\u001b[0m \u001b[38;5;28;43mnext\u001b[39;49m\u001b[43m(\u001b[49m\u001b[43moutput\u001b[49m\u001b[43m)\u001b[49m\n\u001b[1;32m   2007\u001b[0m \u001b[38;5;28;01mreturn\u001b[39;00m output \u001b[38;5;28;01mif\u001b[39;00m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mreturn_generator \u001b[38;5;28;01melse\u001b[39;00m \u001b[38;5;28mlist\u001b[39m(output)\n",
      "File \u001b[0;32m/opt/conda/lib/python3.10/site-packages/joblib/parallel.py:1643\u001b[0m, in \u001b[0;36mParallel._get_outputs\u001b[0;34m(self, iterator, pre_dispatch)\u001b[0m\n\u001b[1;32m   1641\u001b[0m detach_generator_exit \u001b[38;5;241m=\u001b[39m \u001b[38;5;28;01mFalse\u001b[39;00m\n\u001b[1;32m   1642\u001b[0m \u001b[38;5;28;01mtry\u001b[39;00m:\n\u001b[0;32m-> 1643\u001b[0m     \u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43m_start\u001b[49m\u001b[43m(\u001b[49m\u001b[43miterator\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mpre_dispatch\u001b[49m\u001b[43m)\u001b[49m\n\u001b[1;32m   1644\u001b[0m     \u001b[38;5;66;03m# first yield returns None, for internal use only. This ensures\u001b[39;00m\n\u001b[1;32m   1645\u001b[0m     \u001b[38;5;66;03m# that we enter the try/except block and start dispatching the\u001b[39;00m\n\u001b[1;32m   1646\u001b[0m     \u001b[38;5;66;03m# tasks.\u001b[39;00m\n\u001b[1;32m   1647\u001b[0m     \u001b[38;5;28;01myield\u001b[39;00m\n",
      "File \u001b[0;32m/opt/conda/lib/python3.10/site-packages/joblib/parallel.py:1626\u001b[0m, in \u001b[0;36mParallel._start\u001b[0;34m(self, iterator, pre_dispatch)\u001b[0m\n\u001b[1;32m   1617\u001b[0m \u001b[38;5;28;01mdef\u001b[39;00m\u001b[38;5;250m \u001b[39m\u001b[38;5;21m_start\u001b[39m(\u001b[38;5;28mself\u001b[39m, iterator, pre_dispatch):\n\u001b[1;32m   1618\u001b[0m     \u001b[38;5;66;03m# Only set self._iterating to True if at least a batch\u001b[39;00m\n\u001b[1;32m   1619\u001b[0m     \u001b[38;5;66;03m# was dispatched. In particular this covers the edge\u001b[39;00m\n\u001b[0;32m   (...)\u001b[0m\n\u001b[1;32m   1623\u001b[0m     \u001b[38;5;66;03m# was very quick and its callback already dispatched all the\u001b[39;00m\n\u001b[1;32m   1624\u001b[0m     \u001b[38;5;66;03m# remaining jobs.\u001b[39;00m\n\u001b[1;32m   1625\u001b[0m     \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_iterating \u001b[38;5;241m=\u001b[39m \u001b[38;5;28;01mFalse\u001b[39;00m\n\u001b[0;32m-> 1626\u001b[0m     \u001b[38;5;28;01mif\u001b[39;00m \u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mdispatch_one_batch\u001b[49m\u001b[43m(\u001b[49m\u001b[43miterator\u001b[49m\u001b[43m)\u001b[49m:\n\u001b[1;32m   1627\u001b[0m         \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_iterating \u001b[38;5;241m=\u001b[39m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_original_iterator \u001b[38;5;129;01mis\u001b[39;00m \u001b[38;5;129;01mnot\u001b[39;00m \u001b[38;5;28;01mNone\u001b[39;00m\n\u001b[1;32m   1629\u001b[0m     \u001b[38;5;28;01mwhile\u001b[39;00m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mdispatch_one_batch(iterator):\n",
      "File \u001b[0;32m/opt/conda/lib/python3.10/site-packages/joblib/parallel.py:1517\u001b[0m, in \u001b[0;36mParallel.dispatch_one_batch\u001b[0;34m(self, iterator)\u001b[0m\n\u001b[1;32m   1515\u001b[0m     \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[38;5;28;01mFalse\u001b[39;00m\n\u001b[1;32m   1516\u001b[0m \u001b[38;5;28;01melse\u001b[39;00m:\n\u001b[0;32m-> 1517\u001b[0m     \u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43m_dispatch\u001b[49m\u001b[43m(\u001b[49m\u001b[43mtasks\u001b[49m\u001b[43m)\u001b[49m\n\u001b[1;32m   1518\u001b[0m     \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[38;5;28;01mTrue\u001b[39;00m\n",
      "File \u001b[0;32m/opt/conda/lib/python3.10/site-packages/joblib/parallel.py:1418\u001b[0m, in \u001b[0;36mParallel._dispatch\u001b[0;34m(self, batch)\u001b[0m\n\u001b[1;32m   1411\u001b[0m     \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_jobs\u001b[38;5;241m.\u001b[39mappend(batch_tracker)\n\u001b[1;32m   1413\u001b[0m \u001b[38;5;66;03m# If return_ordered is False, the batch_tracker is not stored in the\u001b[39;00m\n\u001b[1;32m   1414\u001b[0m \u001b[38;5;66;03m# jobs queue at the time of submission. Instead, it will be appended to\u001b[39;00m\n\u001b[1;32m   1415\u001b[0m \u001b[38;5;66;03m# the queue by itself as soon as the callback is triggered to be able\u001b[39;00m\n\u001b[1;32m   1416\u001b[0m \u001b[38;5;66;03m# to return the results in the order of completion.\u001b[39;00m\n\u001b[0;32m-> 1418\u001b[0m job \u001b[38;5;241m=\u001b[39m \u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43m_backend\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mapply_async\u001b[49m\u001b[43m(\u001b[49m\u001b[43mbatch\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mcallback\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mbatch_tracker\u001b[49m\u001b[43m)\u001b[49m\n\u001b[1;32m   1419\u001b[0m batch_tracker\u001b[38;5;241m.\u001b[39mregister_job(job)\n",
      "File \u001b[0;32m/opt/conda/lib/python3.10/site-packages/lithops/util/joblib/lithops_backend.py:121\u001b[0m, in \u001b[0;36mLithopsBackend.apply_async\u001b[0;34m(self, func, callback)\u001b[0m\n\u001b[1;32m    119\u001b[0m     \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_get_pool()\u001b[38;5;241m.\u001b[39mapply_async(handle_call_threads, (mem_opt_calls, ), callback\u001b[38;5;241m=\u001b[39mcallback)\n\u001b[1;32m    120\u001b[0m \u001b[38;5;28;01melse\u001b[39;00m:\n\u001b[0;32m--> 121\u001b[0m     \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43m_get_pool\u001b[49m\u001b[43m(\u001b[49m\u001b[43m)\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mstarmap_async\u001b[49m\u001b[43m(\u001b[49m\u001b[43mhandle_call_process\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mmem_opt_calls\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mcallback\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mcallback\u001b[49m\u001b[43m)\u001b[49m\n",
      "File \u001b[0;32m/opt/conda/lib/python3.10/site-packages/lithops/multiprocessing/pool.py:112\u001b[0m, in \u001b[0;36mPool.starmap_async\u001b[0;34m(self, func, iterable, chunksize, callback, error_callback)\u001b[0m\n\u001b[1;32m    108\u001b[0m \u001b[38;5;28;01mdef\u001b[39;00m\u001b[38;5;250m \u001b[39m\u001b[38;5;21mstarmap_async\u001b[39m(\u001b[38;5;28mself\u001b[39m, func, iterable, chunksize\u001b[38;5;241m=\u001b[39m\u001b[38;5;28;01mNone\u001b[39;00m, callback\u001b[38;5;241m=\u001b[39m\u001b[38;5;28;01mNone\u001b[39;00m, error_callback\u001b[38;5;241m=\u001b[39m\u001b[38;5;28;01mNone\u001b[39;00m):\n\u001b[1;32m    109\u001b[0m \u001b[38;5;250m    \u001b[39m\u001b[38;5;124;03m\"\"\"\u001b[39;00m\n\u001b[1;32m    110\u001b[0m \u001b[38;5;124;03m    Asynchronous version of `starmap()` method.\u001b[39;00m\n\u001b[1;32m    111\u001b[0m \u001b[38;5;124;03m    \"\"\"\u001b[39;00m\n\u001b[0;32m--> 112\u001b[0m     \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43m_map_async\u001b[49m\u001b[43m(\u001b[49m\u001b[43mfunc\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43miterable\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mchunksize\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mchunksize\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m    113\u001b[0m \u001b[43m                           \u001b[49m\u001b[43mcallback\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mcallback\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43merror_callback\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43merror_callback\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mstarmap\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[38;5;28;43;01mTrue\u001b[39;49;00m\u001b[43m)\u001b[49m\n",
      "File \u001b[0;32m/opt/conda/lib/python3.10/site-packages/lithops/multiprocessing/pool.py:184\u001b[0m, in \u001b[0;36mPool._map_async\u001b[0;34m(self, func, iterable, chunksize, callback, error_callback, starmap)\u001b[0m\n\u001b[1;32m    173\u001b[0m extra_args \u001b[38;5;241m=\u001b[39m (\n\u001b[1;32m    174\u001b[0m     func,\n\u001b[1;32m    175\u001b[0m     \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_initializer,\n\u001b[0;32m   (...)\u001b[0m\n\u001b[1;32m    179\u001b[0m     \u001b[38;5;124m'\u001b[39m\u001b[38;5;124mstarmap\u001b[39m\u001b[38;5;124m'\u001b[39m \u001b[38;5;28;01mif\u001b[39;00m starmap \u001b[38;5;28;01melse\u001b[39;00m \u001b[38;5;124m'\u001b[39m\u001b[38;5;124mmap\u001b[39m\u001b[38;5;124m'\u001b[39m\n\u001b[1;32m    180\u001b[0m )\n\u001b[1;32m    182\u001b[0m fmt_args \u001b[38;5;241m=\u001b[39m [(arg,) \u001b[38;5;28;01mfor\u001b[39;00m arg \u001b[38;5;129;01min\u001b[39;00m iterable]\n\u001b[0;32m--> 184\u001b[0m futures \u001b[38;5;241m=\u001b[39m \u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43m_executor\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mmap\u001b[49m\u001b[43m(\u001b[49m\u001b[43mcloud_process_wrapper\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m    185\u001b[0m \u001b[43m                             \u001b[49m\u001b[43mfmt_args\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m    186\u001b[0m \u001b[43m                             \u001b[49m\u001b[43mextra_args\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mextra_args\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m    187\u001b[0m \u001b[43m                             \u001b[49m\u001b[43mextra_env\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mextra_env\u001b[49m\u001b[43m)\u001b[49m\n\u001b[1;32m    189\u001b[0m result \u001b[38;5;241m=\u001b[39m MapResult(\u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_executor, futures, callback, error_callback)\n\u001b[1;32m    191\u001b[0m \u001b[38;5;28;01mreturn\u001b[39;00m result\n",
      "File \u001b[0;32m/opt/conda/lib/python3.10/site-packages/lithops/executors.py:272\u001b[0m, in \u001b[0;36mFunctionExecutor.map\u001b[0;34m(self, map_function, map_iterdata, chunksize, extra_args, extra_env, runtime_memory, obj_chunk_size, obj_chunk_number, obj_newline, timeout, include_modules, exclude_modules)\u001b[0m\n\u001b[1;32m    268\u001b[0m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mlast_call \u001b[38;5;241m=\u001b[39m \u001b[38;5;124m'\u001b[39m\u001b[38;5;124mmap\u001b[39m\u001b[38;5;124m'\u001b[39m\n\u001b[1;32m    270\u001b[0m runtime_meta \u001b[38;5;241m=\u001b[39m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39minvoker\u001b[38;5;241m.\u001b[39mselect_runtime(job_id, runtime_memory)\n\u001b[0;32m--> 272\u001b[0m job \u001b[38;5;241m=\u001b[39m \u001b[43mcreate_map_job\u001b[49m\u001b[43m(\u001b[49m\n\u001b[1;32m    273\u001b[0m \u001b[43m    \u001b[49m\u001b[43mconfig\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mconfig\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m    274\u001b[0m \u001b[43m    \u001b[49m\u001b[43minternal_storage\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43minternal_storage\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m    275\u001b[0m \u001b[43m    \u001b[49m\u001b[43mexecutor_id\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mexecutor_id\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m    276\u001b[0m \u001b[43m    \u001b[49m\u001b[43mjob_id\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mjob_id\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m    277\u001b[0m \u001b[43m    \u001b[49m\u001b[43mmap_function\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mmap_function\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m    278\u001b[0m \u001b[43m    \u001b[49m\u001b[43miterdata\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mmap_iterdata\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m    279\u001b[0m \u001b[43m    \u001b[49m\u001b[43mchunksize\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mchunksize\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m    280\u001b[0m \u001b[43m    \u001b[49m\u001b[43mruntime_meta\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mruntime_meta\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m    281\u001b[0m \u001b[43m    \u001b[49m\u001b[43mruntime_memory\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mruntime_memory\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m    282\u001b[0m \u001b[43m    \u001b[49m\u001b[43mextra_env\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mextra_env\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m    283\u001b[0m \u001b[43m    \u001b[49m\u001b[43minclude_modules\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43minclude_modules\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m    284\u001b[0m \u001b[43m    \u001b[49m\u001b[43mexclude_modules\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mexclude_modules\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m    285\u001b[0m \u001b[43m    \u001b[49m\u001b[43mexecution_timeout\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mtimeout\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m    286\u001b[0m \u001b[43m    \u001b[49m\u001b[43mextra_args\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mextra_args\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m    287\u001b[0m \u001b[43m    \u001b[49m\u001b[43mobj_chunk_size\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mobj_chunk_size\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m    288\u001b[0m \u001b[43m    \u001b[49m\u001b[43mobj_chunk_number\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mobj_chunk_number\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m    289\u001b[0m \u001b[43m    \u001b[49m\u001b[43mobj_newline\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mobj_newline\u001b[49m\n\u001b[1;32m    290\u001b[0m \u001b[43m\u001b[49m\u001b[43m)\u001b[49m\n\u001b[1;32m    292\u001b[0m futures \u001b[38;5;241m=\u001b[39m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39minvoker\u001b[38;5;241m.\u001b[39mrun_job(job)\n\u001b[1;32m    293\u001b[0m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mfutures\u001b[38;5;241m.\u001b[39mextend(futures)\n",
      "File \u001b[0;32m/opt/conda/lib/python3.10/site-packages/lithops/job/job.py:81\u001b[0m, in \u001b[0;36mcreate_map_job\u001b[0;34m(config, internal_storage, executor_id, job_id, map_function, iterdata, runtime_meta, runtime_memory, extra_env, include_modules, exclude_modules, execution_timeout, chunksize, extra_args, obj_chunk_size, obj_newline, obj_chunk_number)\u001b[0m\n\u001b[1;32m     78\u001b[0m     host_job_meta[\u001b[38;5;124m'\u001b[39m\u001b[38;5;124mhost_job_create_partitions_time\u001b[39m\u001b[38;5;124m'\u001b[39m] \u001b[38;5;241m=\u001b[39m \u001b[38;5;28mround\u001b[39m(time\u001b[38;5;241m.\u001b[39mtime() \u001b[38;5;241m-\u001b[39m create_partitions_start, \u001b[38;5;241m6\u001b[39m)\n\u001b[1;32m     79\u001b[0m \u001b[38;5;66;03m# ########\u001b[39;00m\n\u001b[0;32m---> 81\u001b[0m job \u001b[38;5;241m=\u001b[39m \u001b[43m_create_job\u001b[49m\u001b[43m(\u001b[49m\n\u001b[1;32m     82\u001b[0m \u001b[43m    \u001b[49m\u001b[43mconfig\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mconfig\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m     83\u001b[0m \u001b[43m    \u001b[49m\u001b[43minternal_storage\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43minternal_storage\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m     84\u001b[0m \u001b[43m    \u001b[49m\u001b[43mexecutor_id\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mexecutor_id\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m     85\u001b[0m \u001b[43m    \u001b[49m\u001b[43mjob_id\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mjob_id\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m     86\u001b[0m \u001b[43m    \u001b[49m\u001b[43mfunc\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mmap_function\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m     87\u001b[0m \u001b[43m    \u001b[49m\u001b[43miterdata\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mmap_iterdata\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m     88\u001b[0m \u001b[43m    \u001b[49m\u001b[43mchunksize\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mchunksize\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m     89\u001b[0m \u001b[43m    \u001b[49m\u001b[43mruntime_meta\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mruntime_meta\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m     90\u001b[0m \u001b[43m    \u001b[49m\u001b[43mruntime_memory\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mruntime_memory\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m     91\u001b[0m \u001b[43m    \u001b[49m\u001b[43mextra_env\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mextra_env\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m     92\u001b[0m \u001b[43m    \u001b[49m\u001b[43minclude_modules\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43minclude_modules\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m     93\u001b[0m \u001b[43m    \u001b[49m\u001b[43mexclude_modules\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mexclude_modules\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m     94\u001b[0m \u001b[43m    \u001b[49m\u001b[43mexecution_timeout\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mexecution_timeout\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m     95\u001b[0m \u001b[43m    \u001b[49m\u001b[43mhost_job_meta\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mhost_job_meta\u001b[49m\n\u001b[1;32m     96\u001b[0m \u001b[43m\u001b[49m\u001b[43m)\u001b[49m\n\u001b[1;32m     98\u001b[0m \u001b[38;5;28;01mif\u001b[39;00m ppo:\n\u001b[1;32m     99\u001b[0m     job\u001b[38;5;241m.\u001b[39mparts_per_object \u001b[38;5;241m=\u001b[39m ppo\n",
      "File \u001b[0;32m/opt/conda/lib/python3.10/site-packages/lithops/job/job.py:265\u001b[0m, in \u001b[0;36m_create_job\u001b[0;34m(config, internal_storage, executor_id, job_id, func, iterdata, runtime_meta, runtime_memory, extra_env, include_modules, exclude_modules, execution_timeout, host_job_meta, chunksize)\u001b[0m\n\u001b[1;32m    262\u001b[0m \u001b[38;5;28;01mif\u001b[39;00m data_limit \u001b[38;5;129;01mand\u001b[39;00m data_size_bytes \u001b[38;5;241m>\u001b[39m data_limit \u001b[38;5;241m*\u001b[39m \u001b[38;5;241m1024\u001b[39m\u001b[38;5;241m*\u001b[39m\u001b[38;5;241m*\u001b[39m\u001b[38;5;241m2\u001b[39m:\n\u001b[1;32m    263\u001b[0m     log_msg \u001b[38;5;241m=\u001b[39m (\u001b[38;5;124m'\u001b[39m\u001b[38;5;124mExecutorID \u001b[39m\u001b[38;5;132;01m{}\u001b[39;00m\u001b[38;5;124m | JobID \u001b[39m\u001b[38;5;132;01m{}\u001b[39;00m\u001b[38;5;124m - Total data exceeded maximum size \u001b[39m\u001b[38;5;124m'\u001b[39m\n\u001b[1;32m    264\u001b[0m                \u001b[38;5;124m'\u001b[39m\u001b[38;5;124mof \u001b[39m\u001b[38;5;132;01m{}\u001b[39;00m\u001b[38;5;124m'\u001b[39m\u001b[38;5;241m.\u001b[39mformat(executor_id, job_id, utils\u001b[38;5;241m.\u001b[39msizeof_fmt(data_limit \u001b[38;5;241m*\u001b[39m \u001b[38;5;241m1024\u001b[39m\u001b[38;5;241m*\u001b[39m\u001b[38;5;241m*\u001b[39m\u001b[38;5;241m2\u001b[39m)))\n\u001b[0;32m--> 265\u001b[0m     \u001b[38;5;28;01mraise\u001b[39;00m \u001b[38;5;167;01mException\u001b[39;00m(log_msg)\n\u001b[1;32m    267\u001b[0m \u001b[38;5;66;03m# Upload function and data\u001b[39;00m\n\u001b[1;32m    268\u001b[0m upload_function \u001b[38;5;241m=\u001b[39m \u001b[38;5;129;01mnot\u001b[39;00m config[backend]\u001b[38;5;241m.\u001b[39mget(\u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mruntime_include_function\u001b[39m\u001b[38;5;124m\"\u001b[39m, \u001b[38;5;28;01mFalse\u001b[39;00m)\n",
      "\u001b[0;31mException\u001b[0m: ExecutorID 983ab7-0 | JobID M000 - Total data exceeded maximum size of 4.0MiB"
     ]
    }
   ],
   "source": [
    "def main(backend, address, mib, refit, jobs):\n",
    "\n",
    "    X, y = load_data(mib)\n",
    "\n",
    "    n_features = 2 ** 18\n",
    "    pipeline = Pipeline([\n",
    "        ('vect', HashingVectorizer(n_features=n_features, alternate_sign=False)),\n",
    "        ('clf', SGDClassifier()),\n",
    "    ])\n",
    "\n",
    "    parameters = {\n",
    "        'vect__norm': ('l1', 'l2'),\n",
    "        'vect__ngram_range': ((1, 1), (1, 2)),\n",
    "        'clf__alpha': (1e-2, 1e-3, 1e-4, 1e-5),\n",
    "        'clf__max_iter': (20, 60, 100, 160),\n",
    "        'clf__penalty': ('l2', 'l1', 'elasticnet')\n",
    "    }\n",
    "\n",
    "    if backend == 'lithops':\n",
    "        from sklearn.model_selection import GridSearchCV\n",
    "        from lithops.util.joblib import register_lithops\n",
    "        register_lithops()\n",
    "        grid_search = GridSearchCV(pipeline, parameters,\n",
    "                                   error_score='raise',\n",
    "                                   refit=refit, cv=5, n_jobs=jobs)\n",
    "\n",
    "    elif backend == 'ray':\n",
    "        from sklearn.model_selection import GridSearchCV\n",
    "        import ray\n",
    "        from ray.util.joblib import register_ray\n",
    "        address = 'auto' if address is None else address\n",
    "        ray.init(address, redis_password='5241590000000000')\n",
    "        register_ray()\n",
    "        grid_search = GridSearchCV(pipeline, parameters,\n",
    "                                   error_score='raise',\n",
    "                                   refit=refit, cv=5, n_jobs=jobs)\n",
    "\n",
    "    elif backend == 'tune':\n",
    "        from tune_sklearn import TuneGridSearchCV\n",
    "        import ray\n",
    "        address = 'auto' if address is None else address\n",
    "        ray.init(address, log_to_driver=False, redis_password='5241590000000000')\n",
    "        grid_search = TuneGridSearchCV(pipeline, parameters,\n",
    "            error_score='raise', refit=refit, cv=5, n_jobs=jobs)\n",
    "        backend = 'loky' # not used\n",
    "\n",
    "    elif backend == 'dask':\n",
    "        from dask_ml.model_selection import GridSearchCV\n",
    "        from dask_ml.feature_extraction.text import HashingVectorizer as DaskHashingVectorizer\n",
    "        from distributed import Client\n",
    "        if address is None:\n",
    "            print('Error: must specify a scheduler address for dask distributed')\n",
    "            exit(1)\n",
    "        Client(address=address)\n",
    "        pipeline = Pipeline([\n",
    "            ('vect', DaskHashingVectorizer(n_features=n_features, alternate_sign=False)),\n",
    "            ('clf', SGDClassifier()),\n",
    "        ])\n",
    "        grid_search = GridSearchCV(pipeline, parameters,\n",
    "            error_score='raise', refit=refit, cv=5, n_jobs=jobs)\n",
    "\n",
    "    else:   # loky\n",
    "        from sklearn.model_selection import GridSearchCV\n",
    "        grid_search = GridSearchCV(pipeline, parameters,\n",
    "            error_score='raise', refit=refit, cv=5, n_jobs=jobs)\n",
    "\n",
    "    print(\"pipeline:\", [name for name, _ in pipeline.steps])\n",
    "    print(\"parameters: \", end='')\n",
    "    pprint(parameters)\n",
    "\n",
    "    with joblib.parallel_backend(backend):\n",
    "        print(\"Performing grid search...\")\n",
    "        t0 = time()\n",
    "        grid_search.fit(X, y)\n",
    "        total_time = time() - t0\n",
    "        print(\"Done in %0.3fs\\n\" % total_time) \n",
    "\n",
    "    if refit:\n",
    "        print(\"Best score: %0.3f\" % grid_search.best_score_)\n",
    "        print(\"Best parameters set:\")\n",
    "        best_parameters = grid_search.best_estimator_.get_params()\n",
    "        for param_name in sorted(parameters.keys()):\n",
    "            print(\"\\t%s: %r\" % (param_name, best_parameters[param_name]))\n",
    "            \n",
    "if __name__ == \"__main__\":\n",
    "    main(\"lithops\", None, 10, False, -1)"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.10.16"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
